{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 03 \n",
    "\n",
    "### General description \n",
    "\n",
    "Mix Jigsaw dataset and CTEC dataset for training. \n",
    "\n",
    "<ul>\n",
    "    <li>Encoding: chars2vec for word embeddings. For sentence embedding, we *naively* sum all the word vectors in a sentence.</li>\n",
    "    <li>Models: logistic regression vs. multilayer perceptrons</li>\n",
    "    <li>Training set: 18386 jigsaw negative + 1614 jigsaw positive + 500 ctec negative + 10000 ctec positive</li>\n",
    "    <li>Test set: 1401 ctec negative + 11600 ctec positive</li>\n",
    "    <li>Metric: ROC AUC score</li>\n",
    "</ul>\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import chars2vec\n",
    "import multiprocessing as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jigsaw # negative examples = 18386\n",
      "jigsaw # positive examples = 1614\n",
      "ctec # negative examples = 1901\n",
      "ctec # positive examples = 21600\n"
     ]
    }
   ],
   "source": [
    "# Load jigsaw and ctec datasets \n",
    "jigsaw_df = pd.read_csv('train_preproc_shrk.csv')\n",
    "ctec_df = pd.read_csv('ctec_training_data_preproc.csv')\n",
    "\n",
    "# target >= 0.5 --> toxic --> label = 1\n",
    "# target < 0.5 --> non-toxic --> label = 0\n",
    "jigsaw_df.loc[jigsaw_df['target'] >= 0.5, 'label'] = 1\n",
    "jigsaw_df.loc[jigsaw_df['target'] < 0.5, 'label'] = 0\n",
    "\n",
    "# Split by label \n",
    "jigsaw_neg = jigsaw_df[jigsaw_df['label'] == 0]\n",
    "jigsaw_pos = jigsaw_df[jigsaw_df['label'] == 1]\n",
    "ctec_neg = ctec_df[ctec_df['label'] == 0]\n",
    "ctec_pos = ctec_df[ctec_df['label'] == 1]\n",
    "\n",
    "# Show number of positive and negative examples in each dataset \n",
    "print(f'jigsaw # negative examples = {jigsaw_neg.shape[0]}')\n",
    "print(f'jigsaw # positive examples = {jigsaw_pos.shape[0]}')\n",
    "print(f'ctec # negative examples = {ctec_neg.shape[0]}')\n",
    "print(f'ctec # positive examples = {ctec_pos.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine the scheme of data combination and train-test-split based on the proportion of positive and negative examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set and test set based on the scheme described above\n",
    "\n",
    "# Randomly sampling indices \n",
    "indpos = np.random.choice(range(ctec_pos.shape[0]), size = 10000, replace = False)\n",
    "indneg = np.random.choice(range(ctec_neg.shape[0]), size = 500, replace = False)\n",
    "notindpos = np.setdiff1d(range(ctec_pos.shape[0]), indpos)\n",
    "notindneg = np.setdiff1d(range(ctec_neg.shape[0]), indneg)\n",
    "\n",
    "# X_train in text format, and y_train\n",
    "# All jigsaw examples plus sampled ctec examples\n",
    "X_train_text = jigsaw_df['comment_text'].append(\n",
    "    ctec_pos['comment_text'].iloc[indpos], \n",
    "    ignore_index = True\n",
    ").append(\n",
    "    ctec_neg['comment_text'].iloc[indneg], \n",
    "    ignore_index = True\n",
    ")\n",
    "\n",
    "y_train = jigsaw_df['label'].append(\n",
    "    ctec_pos['label'].iloc[indpos], \n",
    "    ignore_index = True\n",
    ").append(\n",
    "    ctec_neg['label'].iloc[indneg], \n",
    "    ignore_index = True\n",
    ")\n",
    "\n",
    "# X_test in text format, and y_test \n",
    "X_test_text = ctec_neg['comment_text'].iloc[notindneg].append(\n",
    "    ctec_pos['comment_text'].iloc[notindpos], \n",
    "    ignore_index = True\n",
    ")\n",
    "\n",
    "y_test = ctec_neg['label'].iloc[notindneg].append(\n",
    "    ctec_pos['label'].iloc[notindpos], \n",
    "    ignore_index = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67634\n",
      "54086\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary of training set\n",
    "countvec = CountVectorizer()\n",
    "countvec.fit(X_train_text)\n",
    "vocab_train = list(countvec.vocabulary_.keys())\n",
    "\n",
    "# Vocabulary of test set \n",
    "countvec.fit(X_test_text)\n",
    "vocab_test = list(countvec.vocabulary_.keys())\n",
    "\n",
    "print(len(vocab_train))\n",
    "print(len(vocab_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 training texts have been encoded. Total time elapsed for training set = 93.65556788444519\n",
      "2000 training texts have been encoded. Total time elapsed for training set = 165.1000828742981\n",
      "3000 training texts have been encoded. Total time elapsed for training set = 229.66850686073303\n",
      "4000 training texts have been encoded. Total time elapsed for training set = 292.52003812789917\n",
      "5000 training texts have been encoded. Total time elapsed for training set = 356.16848373413086\n",
      "6000 training texts have been encoded. Total time elapsed for training set = 429.3732364177704\n",
      "7000 training texts have been encoded. Total time elapsed for training set = 497.3414192199707\n",
      "8000 training texts have been encoded. Total time elapsed for training set = 569.1971561908722\n",
      "9000 training texts have been encoded. Total time elapsed for training set = 636.2412085533142\n",
      "10000 training texts have been encoded. Total time elapsed for training set = 709.0072994232178\n",
      "11000 training texts have been encoded. Total time elapsed for training set = 773.325923204422\n",
      "12000 training texts have been encoded. Total time elapsed for training set = 828.424533367157\n",
      "13000 training texts have been encoded. Total time elapsed for training set = 881.3858559131622\n",
      "14000 training texts have been encoded. Total time elapsed for training set = 934.4691617488861\n",
      "15000 training texts have been encoded. Total time elapsed for training set = 992.1791055202484\n",
      "16000 training texts have been encoded. Total time elapsed for training set = 1044.3716826438904\n",
      "17000 training texts have been encoded. Total time elapsed for training set = 1093.8199887275696\n",
      "18000 training texts have been encoded. Total time elapsed for training set = 1144.1804223060608\n",
      "19000 training texts have been encoded. Total time elapsed for training set = 1193.834508895874\n",
      "20000 training texts have been encoded. Total time elapsed for training set = 1241.7927520275116\n",
      "21000 training texts have been encoded. Total time elapsed for training set = 1309.9151406288147\n",
      "22000 training texts have been encoded. Total time elapsed for training set = 1383.3888638019562\n",
      "23000 training texts have been encoded. Total time elapsed for training set = 1453.1269533634186\n",
      "24000 training texts have been encoded. Total time elapsed for training set = 1521.305316209793\n",
      "25000 training texts have been encoded. Total time elapsed for training set = 1577.3899235725403\n",
      "26000 training texts have been encoded. Total time elapsed for training set = 1645.4588723182678\n",
      "27000 training texts have been encoded. Total time elapsed for training set = 1703.498057126999\n",
      "28000 training texts have been encoded. Total time elapsed for training set = 1762.4412286281586\n",
      "29000 training texts have been encoded. Total time elapsed for training set = 1818.987786769867\n",
      "30000 training texts have been encoded. Total time elapsed for training set = 1874.1742317676544\n",
      "1000 training texts have been encoded. Total time elapsed for training set = 47.20455551147461\n",
      "2000 training texts have been encoded. Total time elapsed for training set = 88.21335291862488\n",
      "3000 training texts have been encoded. Total time elapsed for training set = 169.6854772567749\n",
      "4000 training texts have been encoded. Total time elapsed for training set = 217.39619541168213\n",
      "5000 training texts have been encoded. Total time elapsed for training set = 272.3336944580078\n",
      "6000 training texts have been encoded. Total time elapsed for training set = 321.65909481048584\n",
      "7000 training texts have been encoded. Total time elapsed for training set = 372.0694146156311\n",
      "8000 training texts have been encoded. Total time elapsed for training set = 431.5926604270935\n",
      "9000 training texts have been encoded. Total time elapsed for training set = 506.62373447418213\n",
      "10000 training texts have been encoded. Total time elapsed for training set = 580.2609910964966\n",
      "11000 training texts have been encoded. Total time elapsed for training set = 654.2111215591431\n",
      "12000 training texts have been encoded. Total time elapsed for training set = 710.9996063709259\n",
      "13000 training texts have been encoded. Total time elapsed for training set = 775.303876876831\n"
     ]
    }
   ],
   "source": [
    "nDim = 300\n",
    "\n",
    "# Vectorization with chars2vec, 300-dimensional\n",
    "c2v_model = chars2vec.load_model('eng_' + str(nDim))\n",
    "\n",
    "# The cache that maps a word to its encoding \n",
    "cache = {}\n",
    "\n",
    "# Given a sentence, return its sentence embedding vector\n",
    "# Most naive approach: add together \n",
    "def sent2vec(sent): \n",
    "    words = sent.split()\n",
    "    sentVec = np.zeros(nDim)\n",
    "    \n",
    "    for word in words: \n",
    "        # Remove a word from the list if its embedding has already been computed\n",
    "        # Add the word vector to `sentVec`\n",
    "        if word in cache: \n",
    "            words.remove(word)\n",
    "            sentVec += cache[word]\n",
    "            \n",
    "    # Use chars2vec model to calculate word embeddings\n",
    "    veclist = c2v_model.vectorize_words(words)\n",
    "    veclist = np.array(veclist)\n",
    "    \n",
    "    # Calculate the sentence embedding by summing word embeddings\n",
    "    sentVec += np.sum(veclist, axis = 0)\n",
    "    \n",
    "    # Cache the new words \n",
    "    for i in range(len(words)): \n",
    "        cache[words[i]] = veclist[i, :]\n",
    "    \n",
    "    return sentVec\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "X_train_unscaled = []\n",
    "counter = 0\n",
    "startTime = time.time()\n",
    "\n",
    "# Calculate sentence embedding for each text in training set \n",
    "for text in X_train_text: \n",
    "    embedding = sent2vec(text)\n",
    "    X_train_unscaled.append(embedding)\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(f'{counter} training texts have been encoded. Total time elapsed for training set = {time.time() - startTime}', \n",
    "             flush = True)\n",
    "    \n",
    "X_test_unscaled = []\n",
    "counter = 0\n",
    "startTime = time.time()\n",
    "    \n",
    "# Calculate sentence embedding for each text in test set \n",
    "for text in X_test_text:\n",
    "    embedding = sent2vec(text)\n",
    "    X_test_unscaled.append(embedding)\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(f'{counter} training texts have been encoded. Total time elapsed for training set = {time.time() - startTime}', \n",
    "             flush = True)\n",
    "\n",
    "np.savetxt('train_embed.csv', X_train_unscaled, fmt = '%.5f', delimiter=',')\n",
    "np.savetxt('test_embed.csv', X_test_unscaled, fmt = '%.5f', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_unscaled = np.array(X_train_unscaled)\n",
    "X_train_unscaled = np.genfromtxt('train_embed.csv', delimiter = ',')    # Read data from cached files\n",
    "# X_test_unscaled = np.array(X_test_unscaled)\n",
    "X_test_unscaled = np.genfromtxt('test_embed.csv', delimiter = ',')    # Read data from cached files\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 42s, sys: 1min 53s, total: 10min 36s\n",
      "Wall time: 2min 41s\n",
      "\n",
      "Logistic regression\n",
      "best parameter = {'C': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train set</th>\n",
       "      <th>test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.720295</td>\n",
       "      <td>0.457734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confusion matrix</td>\n",
       "      <td>[[17291, 1595], [6936, 4678]]</td>\n",
       "      <td>[[946, 455], [6595, 5005]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.523061</td>\n",
       "      <td>0.586753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC AUC score</td>\n",
       "      <td>0.659168</td>\n",
       "      <td>0.553349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric                      train set                    test set\n",
       "0          accuracy                       0.720295                    0.457734\n",
       "1  confusion matrix  [[17291, 1595], [6936, 4678]]  [[946, 455], [6595, 5005]]\n",
       "2          F1 score                       0.523061                    0.586753\n",
       "3     ROC AUC score                       0.659168                    0.553349"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model and hyperparameterization\n",
    "clf = GridSearchCV(\n",
    "    LogisticRegression(max_iter = 2000), \n",
    "    param_grid = {'C': [0.1, 1, 10]}, \n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "# Train \n",
    "%time clf.fit(X_train, y_train)\n",
    " \n",
    "# Predict label\n",
    "y_train_pred_class = clf.predict(X_train)\n",
    "y_test_pred_class = clf.predict(X_test)\n",
    "# Predict probability of being toxic\n",
    "y_train_pred_prob = clf.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('\\nLogistic regression')\n",
    "print(f'best parameter = {clf.best_params_}')\n",
    "\n",
    "# Store results\n",
    "results = [\n",
    "    [\n",
    "        'accuracy', \n",
    "        metrics.accuracy_score(y_train, y_train_pred_class), \n",
    "        metrics.accuracy_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'confusion matrix', \n",
    "        str(metrics.confusion_matrix(y_train, y_train_pred_class).tolist()), \n",
    "        str(metrics.confusion_matrix(y_test, y_test_pred_class).tolist())\n",
    "    ], \n",
    "    [\n",
    "        'F1 score', \n",
    "        metrics.f1_score(y_train, y_train_pred_class), \n",
    "        metrics.f1_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'ROC AUC score', \n",
    "        metrics.roc_auc_score(y_train, y_train_pred_class), \n",
    "        metrics.roc_auc_score(y_test, y_test_pred_class)\n",
    "    ]\n",
    "]\n",
    "\n",
    "colNames = ['metric', 'train set', 'test set']\n",
    "\n",
    "# Show result \n",
    "pd.DataFrame(results, columns = colNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 2min 40s, total: 6min 2s\n",
      "Wall time: 1min 32s\n",
      "\n",
      "Multilayer Perceptrons\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train set</th>\n",
       "      <th>test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.839279</td>\n",
       "      <td>0.664718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confusion matrix</td>\n",
       "      <td>[[16189, 2697], [2205, 9409]]</td>\n",
       "      <td>[[636, 765], [3594, 8006]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.793339</td>\n",
       "      <td>0.786019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC AUC score</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.572067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric                      train set                    test set\n",
       "0          accuracy                       0.839279                    0.664718\n",
       "1  confusion matrix  [[16189, 2697], [2205, 9409]]  [[636, 765], [3594, 8006]]\n",
       "2          F1 score                       0.793339                    0.786019\n",
       "3     ROC AUC score                       0.833669                    0.572067"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = (50, 10))\n",
    "\n",
    "# Train \n",
    "%time clf.fit(X_train, y_train)\n",
    " \n",
    "# Predict label\n",
    "y_train_pred_class = clf.predict(X_train)\n",
    "y_test_pred_class = clf.predict(X_test)\n",
    "# Predict probability of being toxic\n",
    "y_train_pred_prob = clf.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('\\nMultilayer Perceptrons')\n",
    "# print(f'best parameter = {clf.best_params_}')\n",
    "\n",
    "# Store results\n",
    "results = [\n",
    "    [\n",
    "        'accuracy', \n",
    "        metrics.accuracy_score(y_train, y_train_pred_class), \n",
    "        metrics.accuracy_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'confusion matrix', \n",
    "        str(metrics.confusion_matrix(y_train, y_train_pred_class).tolist()), \n",
    "        str(metrics.confusion_matrix(y_test, y_test_pred_class).tolist())\n",
    "    ], \n",
    "    [\n",
    "        'F1 score', \n",
    "        metrics.f1_score(y_train, y_train_pred_class), \n",
    "        metrics.f1_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'ROC AUC score', \n",
    "        metrics.roc_auc_score(y_train, y_train_pred_class), \n",
    "        metrics.roc_auc_score(y_test, y_test_pred_class)\n",
    "    ]\n",
    "]\n",
    "\n",
    "colNames = ['metric', 'train set', 'test set']\n",
    "\n",
    "# Show result \n",
    "pd.DataFrame(results, columns = colNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More iter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 41s, sys: 20min 47s, total: 50min 28s\n",
      "Wall time: 12min 53s\n",
      "\n",
      "Multilayer Perceptrons\n",
      "best parameter = {'alpha': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train set</th>\n",
       "      <th>test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.734721</td>\n",
       "      <td>0.610415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confusion matrix</td>\n",
       "      <td>[[15588, 3298], [4793, 6821]]</td>\n",
       "      <td>[[682, 719], [4346, 7254]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.627709</td>\n",
       "      <td>0.741225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC AUC score</td>\n",
       "      <td>0.706341</td>\n",
       "      <td>0.55607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric                      train set                    test set\n",
       "0          accuracy                       0.734721                    0.610415\n",
       "1  confusion matrix  [[15588, 3298], [4793, 6821]]  [[682, 719], [4346, 7254]]\n",
       "2          F1 score                       0.627709                    0.741225\n",
       "3     ROC AUC score                       0.706341                     0.55607"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(\n",
    "    MLPClassifier(hidden_layer_sizes = (50, 10), max_iter = 500),\n",
    "    param_grid = {'alpha': [0.01, 0.1, 1, 10]}, \n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "\n",
    "# Train \n",
    "%time clf.fit(X_train, y_train)\n",
    " \n",
    "# Predict label\n",
    "y_train_pred_class = clf.predict(X_train)\n",
    "y_test_pred_class = clf.predict(X_test)\n",
    "# Predict probability of being toxic\n",
    "y_train_pred_prob = clf.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('\\nMultilayer Perceptrons')\n",
    "print(f'best parameter = {clf.best_params_}')\n",
    "\n",
    "# Store results\n",
    "results = [\n",
    "    [\n",
    "        'accuracy', \n",
    "        metrics.accuracy_score(y_train, y_train_pred_class), \n",
    "        metrics.accuracy_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'confusion matrix', \n",
    "        str(metrics.confusion_matrix(y_train, y_train_pred_class).tolist()), \n",
    "        str(metrics.confusion_matrix(y_test, y_test_pred_class).tolist())\n",
    "    ], \n",
    "    [\n",
    "        'F1 score', \n",
    "        metrics.f1_score(y_train, y_train_pred_class), \n",
    "        metrics.f1_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'ROC AUC score', \n",
    "        metrics.roc_auc_score(y_train, y_train_pred_class), \n",
    "        metrics.roc_auc_score(y_test, y_test_pred_class)\n",
    "    ]\n",
    "]\n",
    "\n",
    "colNames = ['metric', 'train set', 'test set']\n",
    "\n",
    "# Show result \n",
    "pd.DataFrame(results, columns = colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
