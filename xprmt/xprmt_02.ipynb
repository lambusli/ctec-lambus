{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 02 \n",
    "\n",
    "### General description \n",
    "\n",
    "Mix Jigsaw dataset and CTEC dataset for training. \n",
    "\n",
    "<ul>\n",
    "    <li>Encoding: TF-IDF</li>\n",
    "    <li>Models: logistic regression vs. multinomial bayesian</li>\n",
    "    <li>Training set: 18386 jigsaw negative + 1614 jigsaw positive + 10000 ctec positive</li>\n",
    "    <li>Test set: 1901 ctec negative + 11600 ctec positive</li>\n",
    "    <li>Metric: ROC AUC score</li>\n",
    "</ul>\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jigsaw # negative examples = 18386\n",
      "jigsaw # positive examples = 1614\n",
      "ctec # negative examples = 1901\n",
      "ctec # positive examples = 21600\n"
     ]
    }
   ],
   "source": [
    "# Load jigsaw and ctec datasets \n",
    "jigsaw_df = pd.read_csv('train_preproc_shrk.csv')\n",
    "ctec_df = pd.read_csv('ctec_training_data_preproc.csv')\n",
    "\n",
    "# target >= 0.5 --> toxic --> label = 1\n",
    "# target < 0.5 --> non-toxic --> label = 0\n",
    "jigsaw_df.loc[jigsaw_df['target'] >= 0.5, 'label'] = 1\n",
    "jigsaw_df.loc[jigsaw_df['target'] < 0.5, 'label'] = 0\n",
    "\n",
    "# Split by label \n",
    "jigsaw_neg = jigsaw_df[jigsaw_df['label'] == 0]\n",
    "jigsaw_pos = jigsaw_df[jigsaw_df['label'] == 1]\n",
    "ctec_neg = ctec_df[ctec_df['label'] == 0]\n",
    "ctec_pos = ctec_df[ctec_df['label'] == 1]\n",
    "\n",
    "# Show number of positive and negative examples in each dataset \n",
    "print(f'jigsaw # negative examples = {jigsaw_neg.shape[0]}')\n",
    "print(f'jigsaw # positive examples = {jigsaw_pos.shape[0]}')\n",
    "print(f'ctec # negative examples = {ctec_neg.shape[0]}')\n",
    "print(f'ctec # positive examples = {ctec_pos.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine the scheme of data combination and train-test-split based on the proportion of positive and negative examples. \n",
    "\n",
    "For now, we take the truncated jigsaw dataset together with 10,000 positive examples of the ctec dataset as the training set. The remaining ctec dataset (11600 positive and 1901 negative) is the test set. In this way, we are able to reach a better balance of the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set and test set based on the scheme described above\n",
    "\n",
    "# Randomly sampling indices \n",
    "ind = np.random.choice(range(ctec_pos.shape[0]), size = 10000, replace = False)\n",
    "notind = np.setdiff1d(range(ctec_pos.shape[0]), ind)\n",
    "\n",
    "# X_train in text format, and y_train\n",
    "# All jigsaw examples plus sampled ctec positive examples\n",
    "X_train_text = jigsaw_df['comment_text'].append(\n",
    "    ctec_pos['comment_text'].iloc[ind], \n",
    "    ignore_index = True\n",
    ")\n",
    "\n",
    "y_train = jigsaw_df['label'].append(\n",
    "    ctec_pos['label'].iloc[ind], \n",
    "    ignore_index = True\n",
    ")\n",
    "\n",
    "# X_test in text format, and y_test \n",
    "X_test_text = ctec_neg['comment_text'].append(\n",
    "    ctec_pos['comment_text'].iloc[notind], \n",
    "    ignore_index = True\n",
    ")\n",
    "\n",
    "y_test = ctec_neg['label'].append(\n",
    "    ctec_pos['label'].iloc[notind], \n",
    "    ignore_index = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization with tfidf\n",
    "encoder = TfidfVectorizer(strip_accents = 'unicode', stop_words = 'english')\n",
    "X_train_unscaled = encoder.fit_transform(X_train_text)\n",
    "X_test_unscaled = encoder.transform(X_test_text)\n",
    "\n",
    "# Normalization without 0-mean\n",
    "scaler = StandardScaler(with_mean = False)\n",
    "X_train = scaler.fit_transform(X_train_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 ms, sys: 979 Âµs, total: 398 ms\n",
      "Wall time: 418 ms\n",
      "\n",
      "Multinomial naive Bayes\n",
      "best parameter = {'alpha': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train set</th>\n",
       "      <th>test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.932767</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confusion matrix</td>\n",
       "      <td>[[18292, 94], [1923, 9691]]</td>\n",
       "      <td>[[811, 1090], [3606, 7994]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.905743</td>\n",
       "      <td>0.772965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC AUC score</td>\n",
       "      <td>0.914656</td>\n",
       "      <td>0.557878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric                    train set                     test set\n",
       "0          accuracy                     0.932767                     0.652174\n",
       "1  confusion matrix  [[18292, 94], [1923, 9691]]  [[811, 1090], [3606, 7994]]\n",
       "2          F1 score                     0.905743                     0.772965\n",
       "3     ROC AUC score                     0.914656                     0.557878"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model and hyperparameterization\n",
    "clf = GridSearchCV(\n",
    "    MultinomialNB(), \n",
    "    param_grid = {'alpha': [0.1, 1, 10]}, \n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "# Train \n",
    "%time clf.fit(X_train, y_train)\n",
    " \n",
    "# Predict label\n",
    "y_train_pred_class = clf.predict(X_train)\n",
    "y_test_pred_class = clf.predict(X_test)\n",
    "# Predict probability of being toxic\n",
    "y_train_pred_prob = clf.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('\\nMultinomial naive Bayes')\n",
    "print(f'best parameter = {clf.best_params_}')\n",
    "\n",
    "# Store results\n",
    "results = [\n",
    "    [\n",
    "        'accuracy', \n",
    "        metrics.accuracy_score(y_train, y_train_pred_class), \n",
    "        metrics.accuracy_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'confusion matrix', \n",
    "        str(metrics.confusion_matrix(y_train, y_train_pred_class).tolist()), \n",
    "        str(metrics.confusion_matrix(y_test, y_test_pred_class).tolist())\n",
    "    ], \n",
    "    [\n",
    "        'F1 score', \n",
    "        metrics.f1_score(y_train, y_train_pred_class), \n",
    "        metrics.f1_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'ROC AUC score', \n",
    "        metrics.roc_auc_score(y_train, y_train_pred_class), \n",
    "        metrics.roc_auc_score(y_test, y_test_pred_class)\n",
    "    ]\n",
    "]\n",
    "\n",
    "colNames = ['metric', 'train set', 'test set']\n",
    "\n",
    "# Show result \n",
    "pd.DataFrame(results, columns = colNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 1min 27s, total: 3min 22s\n",
      "Wall time: 52.4 s\n",
      "\n",
      "Logistic regression\n",
      "best parameter = {'C': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train set</th>\n",
       "      <th>test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.739649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confusion matrix</td>\n",
       "      <td>[[18380, 6], [50, 11564]]</td>\n",
       "      <td>[[390, 1511], [2004, 9596]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>0.845202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC AUC score</td>\n",
       "      <td>0.997684</td>\n",
       "      <td>0.516198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric                  train set                     test set\n",
       "0          accuracy                   0.998133                     0.739649\n",
       "1  confusion matrix  [[18380, 6], [50, 11564]]  [[390, 1511], [2004, 9596]]\n",
       "2          F1 score                   0.997585                     0.845202\n",
       "3     ROC AUC score                   0.997684                     0.516198"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model and hyperparameterization\n",
    "clf = GridSearchCV(\n",
    "    LogisticRegression(max_iter = 2000), \n",
    "    param_grid = {'C': [0.1, 1, 10]}, \n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "# Train \n",
    "%time clf.fit(X_train, y_train)\n",
    " \n",
    "# Predict label\n",
    "y_train_pred_class = clf.predict(X_train)\n",
    "y_test_pred_class = clf.predict(X_test)\n",
    "# Predict probability of being toxic\n",
    "y_train_pred_prob = clf.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('\\nLogistic regression')\n",
    "print(f'best parameter = {clf.best_params_}')\n",
    "\n",
    "# Store results\n",
    "results = [\n",
    "    [\n",
    "        'accuracy', \n",
    "        metrics.accuracy_score(y_train, y_train_pred_class), \n",
    "        metrics.accuracy_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'confusion matrix', \n",
    "        str(metrics.confusion_matrix(y_train, y_train_pred_class).tolist()), \n",
    "        str(metrics.confusion_matrix(y_test, y_test_pred_class).tolist())\n",
    "    ], \n",
    "    [\n",
    "        'F1 score', \n",
    "        metrics.f1_score(y_train, y_train_pred_class), \n",
    "        metrics.f1_score(y_test, y_test_pred_class)\n",
    "    ], \n",
    "    [\n",
    "        'ROC AUC score', \n",
    "        metrics.roc_auc_score(y_train, y_train_pred_class), \n",
    "        metrics.roc_auc_score(y_test, y_test_pred_class)\n",
    "    ]\n",
    "]\n",
    "\n",
    "colNames = ['metric', 'train set', 'test set']\n",
    "\n",
    "# Show result \n",
    "pd.DataFrame(results, columns = colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
